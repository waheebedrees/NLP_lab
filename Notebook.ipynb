{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ffb4876f",
      "metadata": {
        "id": "ffb4876f"
      },
      "source": [
        "# Arabic SA with LSTM and LLMs\n",
        "\n",
        "===============================================\n",
        "Focus:\n",
        "\n",
        "1. LSTM with LLMs embedding\n",
        "\n",
        "2. Fine-tuning LLM for Arabic SA and evaluation (with Arabic tweets data).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "345551ce",
      "metadata": {
        "id": "345551ce"
      },
      "source": [
        "## Part (1) LSTM with LLM embeddings for Arabic SA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "HvD7EM5ROkFx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvD7EM5ROkFx",
        "outputId": "7c70d95f-0a20-45aa-ab01-8255930187bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_lab'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 0), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (5/5), 967.81 KiB | 3.02 MiB/s, done.\n",
            "/content/NLP_lab\n"
          ]
        }
      ],
      "source": [
        "! git clone  https://github.com/waheebedrees/NLP_lab.git\n",
        "\n",
        "%cd  NLP_lab/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "34019887",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34019887",
        "outputId": "d94a7f17-89c5-4c3f-9439-76a262bf6559"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                               tweet  label\n",
              " 0  اغلاق_المحلات_9_مساءمو كافي تقفل كل شوي عشان ا...      0\n",
              " 1  إغلاق_المحلات_9_مساء لكل قرار سلبيات وإيجابيات...      0\n",
              " 2  اغلاق_المحلات_9_مساء المولات بالذات قد تكون ال...      0\n",
              " 3  اغلاق_المحلات_9_مساء طيب متى يفتح المحل السادس...      0\n",
              " 4  اغلاق_المحلات_9_مساء وبما أن الجو اليوم حلو با...      0,\n",
              "    ano3  ano2  ano1  agree text_label  label  \\\n",
              " 0     1     1     1      1   positive      1   \n",
              " 1     1     1     1      1   positive      1   \n",
              " 2     1     1     1      1   positive      1   \n",
              " 3     0     0     0      1   negative      0   \n",
              " 4     0     0     0      1   negative      0   \n",
              " \n",
              "                                                tweet  \n",
              " 0  @ @ @ مطار حمد الدولي ينضم لنادي الخمس نجوم، م...  \n",
              " 1  @ بيض الله وجه إدارة المطار على حسن الاستقبال ...  \n",
              " 2  @ مبادرة مميزة وغير مستغربه من إدارة مطار حمد ...  \n",
              " 3  @ نرجو من إدارة مطار حمد عمل خطة بديلة لأحتكار...  \n",
              " 4  @ نرجو من إدارة مطار حمد عمل خطة بديلة لأحتكار...  )"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "def seed(seed: int = 42):\n",
        "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "seed()\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# This is a version of BERT model trained for Arabic SA\n",
        "MODEL_NAME = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"\n",
        "\n",
        "train_data = pd.read_excel(\"AraSenti_all.xlsx\")\n",
        "\n",
        "test_data = pd.read_excel(\"HIAQatar_tweets.xlsx\")\n",
        "\n",
        "train_data.head(), test_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f608d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "5f608d24",
        "outputId": "e3718024-9c86-4f71-a898-14c9c16ffc73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15751 entries, 0 to 15750\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   tweet   15751 non-null  object\n",
            " 1   label   15751 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 246.2+ KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              label\n",
              "count  15751.000000\n",
              "mean       0.903752\n",
              "std        0.822234\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        1.000000\n",
              "75%        2.000000\n",
              "max        2.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0898ba5-ead4-4efd-ad34-577acf6d90d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15751.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.903752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.822234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0898ba5-ead4-4efd-ad34-577acf6d90d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0898ba5-ead4-4efd-ad34-577acf6d90d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0898ba5-ead4-4efd-ad34-577acf6d90d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(train_data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5568.479793319042,\n        \"min\": 0.0,\n        \"max\": 15751.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          15751.0,\n          0.903752142721097,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tweet    0\n",
              "label    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tweet</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(train_data.describe(), train_data.info(), train_data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8e9218c8",
      "metadata": {
        "id": "8e9218c8"
      },
      "outputs": [],
      "source": [
        "train_data.dropna(inplace=True)\n",
        "test_data.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8c9f616b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "8c9f616b",
        "outputId": "86d649a8-5107-49ed-dc92-751cd2f9bdc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet    اغلاق_المحلات_9_مساءمو كافي تقفل كل شوي عشان ا...\n",
              "label                                                    0\n",
              "Name: 0, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tweet</th>\n",
              "      <td>اغلاق_المحلات_9_مساءمو كافي تقفل كل شوي عشان ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_data.iloc[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e2249ce8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "e2249ce8",
        "outputId": "a31f9a83-fff1-4576-b4d7-fb34792a4387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "0    6155\n",
              "1    4957\n",
              "2    4639\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data.label.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cf751098",
      "metadata": {
        "id": "cf751098"
      },
      "outputs": [],
      "source": [
        "# this will use it later for inverse mapping\n",
        "\n",
        "inverse_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "\n",
        "\n",
        "def mapping(\n",
        "    x): return \"negative\" if x == 0 else \"neutral\" if x == 1 else \"positive\" if x == 2 else -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0c0166cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "0c0166cd",
        "outputId": "21fe4cf4-a3e4-4692-85d9-9b3a4336a0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "هذتيتيتا مثال علي تنظيف التغريدات\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet  label  \\\n",
              "0  اغلاق_المحلات_9_مساءمو كافي تقفل كل شوي عشان ا...      0   \n",
              "1  إغلاق_المحلات_9_مساء لكل قرار سلبيات وإيجابيات...      0   \n",
              "2  اغلاق_المحلات_9_مساء المولات بالذات قد تكون ال...      0   \n",
              "3  اغلاق_المحلات_9_مساء طيب متى يفتح المحل السادس...      0   \n",
              "4  اغلاق_المحلات_9_مساء وبما أن الجو اليوم حلو با...      0   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  اغلاق المحلات مساءمو كافي تقفل كل شوي عشان الص...  \n",
              "1  اغلاق المحلات مساء لكل قرار سلبيات وايجابيات ا...  \n",
              "2  اغلاق المحلات مساء المولات بالذات قد تكون المت...  \n",
              "3  اغلاق المحلات مساء طيب متي يفتح المحل السادسه ...  \n",
              "4  اغلاق المحلات مساء وبما ان الجو اليوم حلو بالس...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6f12c64-a339-498f-8376-5c1d6045635d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اغلاق_المحلات_9_مساءمو كافي تقفل كل شوي عشان ا...</td>\n",
              "      <td>0</td>\n",
              "      <td>اغلاق المحلات مساءمو كافي تقفل كل شوي عشان الص...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>إغلاق_المحلات_9_مساء لكل قرار سلبيات وإيجابيات...</td>\n",
              "      <td>0</td>\n",
              "      <td>اغلاق المحلات مساء لكل قرار سلبيات وايجابيات ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اغلاق_المحلات_9_مساء المولات بالذات قد تكون ال...</td>\n",
              "      <td>0</td>\n",
              "      <td>اغلاق المحلات مساء المولات بالذات قد تكون المت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اغلاق_المحلات_9_مساء طيب متى يفتح المحل السادس...</td>\n",
              "      <td>0</td>\n",
              "      <td>اغلاق المحلات مساء طيب متي يفتح المحل السادسه ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>اغلاق_المحلات_9_مساء وبما أن الجو اليوم حلو با...</td>\n",
              "      <td>0</td>\n",
              "      <td>اغلاق المحلات مساء وبما ان الجو اليوم حلو بالس...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6f12c64-a339-498f-8376-5c1d6045635d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6f12c64-a339-498f-8376-5c1d6045635d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6f12c64-a339-498f-8376-5c1d6045635d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 15751,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15712,\n        \"samples\": [\n          \"\\u0644\\u0644\\u0627\\u0633\\u0641 \\u0627\\u0646\\u0647 \\u0627\\u0633\\u062a\\u0627\\u0630 \\u0628\\u0642\\u0633\\u0645 \\u0627\\u0644\\u0627\\u0639\\u0644\\u0627\\u0645 \\u0648\\u0647\\u0645 \\u0645\\u0646 \\u064a\\u0641\\u062a\\u0631\\u0636 \\u0627\\u0646 \\u064a\\u062a\\u0642\\u0628\\u0644\\u0648 \\u0627\\u0631\\u0627\\u0621 \\u0627\\u0644\\u0627\\u062e\\u0631\\u064a\\u0646 \\u0645\\u0646 \\u0641\\u0636\\u0644 \\u0627\\u0644\\u0644\\u0647 \\u062f\\u0631\\u0633\\u062a \\u0639\\u0646\\u062f \\u0643\\u0644 \\u0627\\u0633\\u0627\\u062a\\u0630\\u0647 \\u0627\\u0644\\u0642\\u0633\\u0645 \\u0627\\u0644\\u0627 \\u0647\\u0648\",\n          \"\\u0628\\u0627\\u0644\\u0635\\u0648\\u0631.. \\u0641\\u0631\\u0633\\u0627\\u0646 \\u0645\\u0643\\u0629 \\u0636\\u0631\\u0628\\u0648\\u0627 \\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\\u064a \\u0628\\u0631\\u0623\\u0633\\u064a\\u0629 \\u0648\\u062e\\u0637\\u0641\\u0648\\u0627 \\u0627\\u0644\\u0646\\u0642\\u0637\\u0629\",\n          \"\\u0635\\u062d\\u064a\\u062d 100 % \\u0648\\u0644\\u0648 \\u0633\\u0627\\u0631\\u062a \\u062e\\u0635\\u062e\\u0635\\u0629 \\u0644\\u0644\\u062a\\u0639\\u0644\\u064a\\u0645 \\u0648\\u0627\\u0644\\u0635\\u062d\\u0629 \\u0628\\u062a\\u0643\\u0648\\u0646 \\u0643\\u0627\\u0631\\u062b\\u0629 \\u0627\\u0644\\u0635\\u0646\\u0627\\u0639\\u0629 \\u0648\\u0627\\u0644\\u0632\\u0631\\u0627\\u0639\\u0647 \\u0648\\u0627\\u0644\\u062b\\u0631\\u0648\\u0629 \\u0627\\u0644\\u062d\\u064a\\u0648\\u0627\\u0646\\u064a\\u0629 \\u0627\\u0644\\u0633\\u0639\\u0648\\u062f\\u064a\\u0629 \\u0635\\u0641\\u0631 \\u0644\\u0644\\u0627\\u0633\\u0641\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15657,\n        \"samples\": [\n          \"\\u0644\\u0627\\u0633\\u0641 \\u0627\\u0630\\u0627 \\u062a\\u0632\\u0648\\u062c\\u0648\\u0627 \\u0637\\u064a\\u0631\\u0648\\u0627 \\u0627\\u0644\\u062d\\u0628 \\u0648\\u0644\\u0637\\u0627\\u0641\\u0647 \\u0627\\u0644\\u0645\\u0631\\u0627\\u0647 \\u0627\\u0644\\u0633\\u0639\\u0648\\u062f\\u064a \\u0640 \\u0627\\u062c\\u0645\\u0644 \\u0640 \\u0648\\u0627\\u0644\\u0637\\u0641 \\u0640 \\u0627\\u0646\\u0633\\u0627\\u0646\",\n          \"\\u0627\\u063a\\u0644\\u0627\\u0642 \\u0627\\u0644\\u0645\\u062d\\u0644\\u0627\\u062a \\u0645\\u0633\\u0627\\u0621\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645 \\u0628\\u0627\\u0632\\u0645\\u0647 \\u0648\\u0634\\u062d \\u0627\\u0642\\u062a\\u0635\\u0627\\u062f\\u064a\\u0627\\u0644\\u062a\\u062c\\u0627\\u0631 \\u064a\\u0628\\u062d\\u062b\\u0648\\u0646 \\u0639\\u0646 \\u0632\\u064a\\u0627\\u062f\\u0647 \\u0633\\u0627\\u0639\\u0627\\u062a \\u0627\\u0644\\u0639\\u0645\\u0644 \\u0648\\u0627\\u0646\\u062a\\u0645 \\u062a\\u0642\\u0648\\u0644\\u0648\\u0627\\u0644\\u0633\\u0627\\u0639\\u0647 \\u0644\\u0627\\u0645\\u0646\\u0637\\u0642\\u064a\\u0647\\u062d\\u062f\\u062b \\u0627\\u0644\\u062a\\u0627\\u062c\\u0631 \\u0628\\u0645\\u0627 \\u064a\\u0631\\u062d\\u0628\",\n          \"\\u0645\\u0646\\u0637\\u0644\\u0642 \\u0627\\u0644\\u0633\\u0648\\u0627\\u0644 \\u062e\\u0637\\u0627 \\u0648\\u0644\\u0630\\u0627 \\u0627\\u0646\\u062a \\u0627\\u062f\\u062e\\u0644\\u062a \\u0646\\u0641\\u0633\\u0643 \\u0641\\u064a \\u0627\\u0644\\u0645\\u0646\\u0627\\u0641\\u0633\\u0647 \\u0628\\u0627\\u0644\\u062a\\u0628\\u0639\\u064a\\u0647 \\u0644\\u062a\\u0631\\u0643\\u064a\\u0628 \\u0627\\u0644\\u0633\\u0648\\u0627\\u0644\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import re\n",
        "# Data preprocessing function\n",
        "# In this function you should clean the Arabic text and normlize it\n",
        "# remove repeated letter, english letter, punctuation, etc.\n",
        "# Input: unclean tweet\n",
        "# Output: clean tweet\n",
        "\n",
        "\n",
        "def clean_tweet(tweet: str) -> str:\n",
        "    '''\n",
        "    write your code here\n",
        "    '''\n",
        "    tweet = str(tweet)\n",
        "\n",
        "    # remove english letters\n",
        "    tweet = re.sub(r'[a-zA-Z0-9]+', '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "    # remove emoijis\n",
        "    tweet = re.sub(\n",
        "        \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "        \"]+\",\n",
        "        \"\",\n",
        "        tweet\n",
        "    )\n",
        "\n",
        "    # Remove URLs\n",
        "    tweet = re.sub(r'http\\S+|www\\S+|pic\\.twitter\\S+', '', tweet)\n",
        "\n",
        "    # remove mentions\n",
        "    tweet = re.sub(r'@\\w+', '', tweet)\n",
        "    # remove hashtags\n",
        "    tweet = re.sub(r'#\\w+', '', tweet)\n",
        "    # Remove digits\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "\n",
        "    # Remove extra symbols and punctuation\n",
        "    # This keeps only letters, numbers, and spaces\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "\n",
        "    # Remove repeated letters\n",
        "    # https://stackoverflow.com/questions/39137851/how-to-deal-with-repeated-letters-in-arabic\n",
        "    tweet = re.sub(r'(.)\\1+', r'\\1', tweet)\n",
        "\n",
        "    # Replace underscores and hyphens with spaces\n",
        "    tweet = re.sub(r'[_\\-]', ' ', tweet)\n",
        "\n",
        "    # Keep only Arabic letters and spaces\n",
        "    tweet = re.sub(r'[^\\u0600-\\u06FF\\s]', '', tweet)\n",
        "\n",
        "    # Remove HTML entities\n",
        "    tweet = re.sub(r'&[a-z]+;', '', tweet)\n",
        "    # Remove extra whitespaces\n",
        "\n",
        "    tweet = normalize_arabic(tweet)\n",
        "\n",
        "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
        "    return tweet\n",
        "\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    # Normalize different forms of Alef\n",
        "    text = re.sub(r'[إأآا]', 'ا', text)\n",
        "    # Normalize Yeh\n",
        "    text = re.sub(r'[يى]', 'ي', text)\n",
        "    # Normalize Teh Marbuta\n",
        "    text = re.sub(r'ة', 'ه', text)\n",
        "    # Normalize Hamza\n",
        "    text = re.sub(r'ؤ', 'و', text)\n",
        "    text = re.sub(r'ئ', 'ي', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "# Test the function\n",
        "text = \"هذتيتيتا مثال على تنظيف التغريدات!!! Visit https://example.com #مثال @user\"\n",
        "cleaned_text = clean_tweet(text)\n",
        "print(cleaned_text)\n",
        "\n",
        "\n",
        "train_data['cleaned_text'] = train_data['tweet'].apply(clean_tweet)\n",
        "test_data['cleaned_text'] = test_data['tweet'].apply(clean_tweet)\n",
        "train_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "_EwB7AcWQYeW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EwB7AcWQYeW",
        "outputId": "c3571152-207e-4f56-f5bd-924b46cabb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data size: 15751\n",
            "test data size: 151\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X = list(train_data['cleaned_text'])\n",
        "y = list(train_data['label'])\n",
        "print(f\"train data size: {len(X)}\")\n",
        "print(f\"test data size: {len(test_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "71b3d1d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71b3d1d0",
        "outputId": "58f8db22-a986-4f20-b022-9365530acdf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('اغلاق المحلات مساءمو كافي تقفل كل شوي عشان الصلاه متي يتسوقون الناس اجل',\n",
              " 'اغلاق_المحلات_9_مساءمو كافي تقفل كل شوي عشان الصلاة متى يتسوقون الناس اجل?')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data['cleaned_text'].iloc[0], train_data['tweet'].iloc[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# Check for exact duplicates\n",
        "def check_exact_duplicates(train_df, val_df, test_df, text_col='cleaned_text'):\n",
        "\n",
        "    train_texts = set(train_df[text_col])\n",
        "    val_texts = set(val_df[text_col])\n",
        "    test_texts = set(test_df[text_col])\n",
        "\n",
        "    train_val_dups = train_texts.intersection(val_texts)\n",
        "    train_test_dups = train_texts.intersection(test_texts)\n",
        "    val_test_dups = val_texts.intersection(test_texts)\n",
        "\n",
        "    return {\n",
        "        'train_val_exact_dups': len(train_val_dups),\n",
        "        'train_test_exact_dups': len(train_test_dups),\n",
        "        'val_test_exact_dups': len(val_test_dups),\n",
        "        'train_val_dup_examples': list(train_val_dups)[:3] if train_val_dups else [],\n",
        "        'train_test_dup_examples': list(train_test_dups)[:3] if train_test_dups else [],\n",
        "        'val_test_dup_examples': list(val_test_dups)[:3] if val_test_dups else []\n",
        "    }\n",
        "\n",
        "def check_data_leakage(train_texts, val_texts, test_texts, threshold=0.9):\n",
        "    \"\"\"Check for overlapping texts between splits using TF-IDF similarity\"\"\"\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    import scipy.sparse as sp\n",
        "\n",
        "    vectorizer = TfidfVectorizer(max_features=5000)\n",
        "    all_texts = list(train_texts) + list(val_texts) + list(test_texts)\n",
        "\n",
        "    # Create a matrix where each row is a document\n",
        "    X = vectorizer.fit_transform(all_texts)\n",
        "\n",
        "    # Check for duplicates\n",
        "    n_train = len(train_texts)\n",
        "    n_val = len(val_texts)\n",
        "    n_test = len(test_texts)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Check train-val overlap\n",
        "    train_matrix = X[:n_train]\n",
        "    val_matrix = X[n_train:n_train+n_val]\n",
        "    similarity = train_matrix @ val_matrix.T\n",
        "    max_similarities = similarity.max(axis=1).toarray().flatten()\n",
        "    results['train_val_max_sim'] = max_similarities.max()\n",
        "    results['train_val_high_sim'] = (max_similarities > threshold).sum()\n",
        "\n",
        "    # Check train-test overlap\n",
        "    test_matrix = X[n_train+n_val:]\n",
        "    similarity = train_matrix @ test_matrix.T\n",
        "    max_similarities = similarity.max(axis=1).toarray().flatten()\n",
        "    results['train_test_max_sim'] = max_similarities.max()\n",
        "    results['train_test_high_sim'] = (max_similarities > threshold).sum()\n",
        "\n",
        "    # Check val-test overlap\n",
        "    similarity = val_matrix @ test_matrix.T\n",
        "    max_similarities = similarity.max(axis=1).toarray().flatten()\n",
        "    results['val_test_max_sim'] = max_similarities.max()\n",
        "    results['val_test_high_sim'] = (max_similarities > threshold).sum()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def plot_label_distribution(train_labels, val_labels, test_labels):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    splits = ['Train', 'Validation', 'Test']\n",
        "    label_data = [train_labels, val_labels, test_labels]\n",
        "\n",
        "    for idx, (ax, split_name, labels) in enumerate(zip(axes, splits, label_data)):\n",
        "        unique, counts = np.unique(labels, return_counts=True)\n",
        "        ax.bar([mapping(l) for l in unique], counts)\n",
        "        ax.set_title(f'{split_name} Set (n={len(labels)})')\n",
        "        ax.set_xlabel('Label')\n",
        "        ax.set_ylabel('Count')\n",
        "        for i, v in enumerate(counts):\n",
        "            ax.text(i, v + max(counts)*0.01, str(v), ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def data_preprocess():\n",
        "    # Load and prepare data\n",
        "    print(\"=\"*60)\n",
        "    print(\"DATA PREPARATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    train_data = pd.read_excel(\"AraSenti_all.xlsx\")\n",
        "    test_data = pd.read_excel(\"HIAQatar_tweets.xlsx\")\n",
        "\n",
        "    print(f\"Original train data size: {len(train_data)}\")\n",
        "    print(f\"Original test data size: {len(test_data)}\")\n",
        "\n",
        "    # Clean data\n",
        "    print(\"\\nCleaning data...\")\n",
        "    train_data['cleaned_text'] = train_data['tweet'].apply(clean_tweet)\n",
        "    test_data['cleaned_text'] = test_data['tweet'].apply(clean_tweet)\n",
        "\n",
        "    train_data = train_data.dropna(subset=['cleaned_text', 'label'])\n",
        "    test_data = test_data.dropna(subset=['cleaned_text', 'label'])\n",
        "\n",
        "    # Remove empty strings\n",
        "    train_data = train_data[train_data['cleaned_text'].str.strip() != '']\n",
        "    test_data = test_data[test_data['cleaned_text'].str.strip() != '']\n",
        "\n",
        "    # Remove duplicates\n",
        "    print(\"\\nRemoving duplicates...\")\n",
        "    train_data = train_data.drop_duplicates(subset=['cleaned_text'])\n",
        "    test_data = test_data.drop_duplicates(subset=['cleaned_text'])\n",
        "\n",
        "    print(f\"After cleaning - Train size: {len(train_data)}\")\n",
        "    print(f\"After cleaning - Test size: {len(test_data)}\")\n",
        "\n",
        "    print(\"\\nSplitting data...\")\n",
        "    train_df, val_df = train_test_split(\n",
        "        train_data,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=train_data['label']\n",
        "    )\n",
        "\n",
        "    print(f\"Train size: {len(train_df)}\")\n",
        "    print(f\"Validation size: {len(val_df)}\")\n",
        "    print(f\"Test size: {len(test_data)}\")\n",
        "\n",
        "\n",
        "    # ============ DATA LEAKAGE CHECK ============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA LEAKAGE CHECK\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    exact_dup_results = check_exact_duplicates(train_df, val_df, test_data, text_col='cleaned_text')\n",
        "    print(\"\\nExact duplicates check:\")\n",
        "    print(f\"Train-Val exact duplicates: {exact_dup_results['train_val_exact_dups']}\")\n",
        "    print(f\"Train-Test exact duplicates: {exact_dup_results['train_test_exact_dups']}\")\n",
        "    print(f\"Val-Test exact duplicates: {exact_dup_results['val_test_exact_dups']}\")\n",
        "\n",
        "    if exact_dup_results['train_val_exact_dups'] > 0:\n",
        "        print(\"\\nWARNING: Found exact duplicates between train and validation!\")\n",
        "        print(\"Examples:\", exact_dup_results['train_val_dup_examples'][:3])\n",
        "\n",
        "    if exact_dup_results['train_test_exact_dups'] > 0:\n",
        "        print(\"\\nWARNING: Found exact duplicates between train and test!\")\n",
        "        print(\"Examples:\", exact_dup_results['train_test_dup_examples'][:3])\n",
        "\n",
        "    if exact_dup_results['val_test_exact_dups'] > 0:\n",
        "        print(\"\\nWARNING: Found exact duplicates between validation and test!\")\n",
        "        print(\"Examples:\", exact_dup_results['val_test_dup_examples'][:3])\n",
        "\n",
        "    # Check similar texts (TF-IDF similarity)\n",
        "    print(\"\\nChecking for similar texts (TF-IDF similarity > 0.9)...\")\n",
        "    similarity_results = check_data_leakage(\n",
        "        train_df['cleaned_text'],\n",
        "        val_df['cleaned_text'],\n",
        "        test_data['cleaned_text'],\n",
        "        threshold=0.9\n",
        "    )\n",
        "\n",
        "    print(f\"Max similarity train-val: {similarity_results['train_val_max_sim']:.4f}\")\n",
        "    print(f\"Documents with >0.9 similarity train-val: {similarity_results['train_val_high_sim']}\")\n",
        "    print(f\"Max similarity train-test: {similarity_results['train_test_max_sim']:.4f}\")\n",
        "    print(f\"Documents with >0.9 similarity train-test: {similarity_results['train_test_high_sim']}\")\n",
        "    print(f\"Max similarity val-test: {similarity_results['val_test_max_sim']:.4f}\")\n",
        "    print(f\"Documents with >0.9 similarity val-test: {similarity_results['val_test_high_sim']}\")\n",
        "\n",
        "    # ============ LABEL DISTRIBUTION CHECK ============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LABEL DISTRIBUTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    train_labels = train_df['label'].values\n",
        "    val_labels = val_df['label'].values\n",
        "    test_labels = test_data['label'].values\n",
        "\n",
        "    print(\"\\nLabel counts:\")\n",
        "    print(\"Train:\", pd.Series(train_labels).value_counts().sort_index().to_dict())\n",
        "    print(\"Validation:\", pd.Series(val_labels).value_counts().sort_index().to_dict())\n",
        "    print(\"Test:\", pd.Series(test_labels).value_counts().sort_index().to_dict())\n",
        "\n",
        "    print(\"\\nLabel percentages:\")\n",
        "    print(\"Train:\", (pd.Series(train_labels).value_counts(normalize=True).sort_index() * 100).round(2).to_dict())\n",
        "    print(\"Validation:\", (pd.Series(val_labels).value_counts(normalize=True).sort_index() * 100).round(2).to_dict())\n",
        "    print(\"Test:\", (pd.Series(test_labels).value_counts(normalize=True).sort_index() * 100).round(2).to_dict())\n",
        "\n",
        "\n",
        "    # Plot label distribution\n",
        "    plot_label_distribution(train_labels, val_labels, test_labels)\n",
        "\n",
        "    # Compute class weights for imbalanced data\n",
        "    class_weights = compute_class_weight(\n",
        "        class_weight='balanced',\n",
        "        classes=np.unique(train_labels),\n",
        "        y=train_labels\n",
        "    )\n",
        "    print(f\"\\nClass weights (for handling imbalance): {class_weights}\")\n",
        "\n",
        "    # ============ DATA QUALITY CHECKS ============\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"DATA QUALITY CHECKS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Check text lengths\n",
        "    train_lengths = train_df['cleaned_text'].str.len()\n",
        "    val_lengths = val_df['cleaned_text'].str.len()\n",
        "    test_lengths = test_data['cleaned_text'].str.len()\n",
        "\n",
        "    print(f\"\\nText length statistics (characters):\")\n",
        "    print(f\"Train - Min: {train_lengths.min()}, Max: {train_lengths.max()}, Mean: {train_lengths.mean():.1f}\")\n",
        "    print(f\"Validation - Min: {val_lengths.min()}, Max: {val_lengths.max()}, Mean: {val_lengths.mean():.1f}\")\n",
        "    print(f\"Test - Min: {test_lengths.min()}, Max: {test_lengths.max()}, Mean: {test_lengths.mean():.1f}\")\n",
        "\n",
        "\n",
        "    # Check for very short texts\n",
        "    short_threshold = 3\n",
        "    train_short = (train_lengths < short_threshold).sum()\n",
        "    val_short = (val_lengths < short_threshold).sum()\n",
        "    test_short = (test_lengths < short_threshold).sum()\n",
        "    print(f\"\\nText length statistics (characters):\")\n",
        "    print(f\"Train - Min: {train_lengths.min()}, Max: {train_lengths.max()}, Mean: {train_lengths.mean():.1f}\")\n",
        "    print(f\"Validation - Min: {val_lengths.min()}, Max: {val_lengths.max()}, Mean: {val_lengths.mean():.1f}\")\n",
        "    print(f\"Test - Min: {test_lengths.min()}, Max: {test_lengths.max()}, Mean: {test_lengths.mean():.1f}\")\n",
        "\n",
        "    if train_short > 0 or val_short > 0 or test_short > 0:\n",
        "        print(f\"\\nWARNING: Found very short texts (<{short_threshold} chars):\")\n",
        "        print(f\"Train: {train_short}, Validation: {val_short}, Test: {test_short}\")\n",
        "\n",
        "    # Sample some texts for manual inspection\n",
        "    print(\"\\nSample texts from each set:\")\n",
        "    print(\"\\nTrain sample:\")\n",
        "    for i in range(min(2, len(train_df))):\n",
        "        print(f\"  {i+1}. {train_df.iloc[i]['cleaned_text'][:100]}... (label: {mapping(train_df.iloc[i]['label'])})\")\n",
        "\n",
        "    print(\"\\nValidation sample:\")\n",
        "    for i in range(min(2, len(val_df))):\n",
        "        print(f\"  {i+1}. {val_df.iloc[i]['cleaned_text'][:100]}... (label: {mapping(val_df.iloc[i]['label'])})\")\n",
        "\n",
        "    print(\"\\nTest sample:\")\n",
        "    for i in range(min(2, len(test_data))):\n",
        "        print(f\"  {i+1}. {test_data.iloc[i]['cleaned_text'][:100]}... (label: {mapping(test_data.iloc[i]['label'])})\")\n",
        "    return train_df, val_df, test_data, class_weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_df, val_df, test_df, class_weights = data_preprocess()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kckabswaK_-p",
        "outputId": "136b7d9b-0271-48c6-a8f9-fec189d099f9"
      },
      "id": "kckabswaK_-p",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATA PREPARATION\n",
            "============================================================\n",
            "Original train data size: 15751\n",
            "Original test data size: 151\n",
            "\n",
            "Cleaning data...\n",
            "\n",
            "Removing duplicates...\n",
            "After cleaning - Train size: 15657\n",
            "After cleaning - Test size: 98\n",
            "\n",
            "Splitting data...\n",
            "Train size: 12525\n",
            "Validation size: 3132\n",
            "Test size: 98\n",
            "\n",
            "============================================================\n",
            "DATA LEAKAGE CHECK\n",
            "============================================================\n",
            "\n",
            "Exact duplicates check:\n",
            "Train-Val exact duplicates: 0\n",
            "Train-Test exact duplicates: 0\n",
            "Val-Test exact duplicates: 0\n",
            "\n",
            "Checking for similar texts (TF-IDF similarity > 0.9)...\n",
            "Max similarity train-val: 1.0000\n",
            "Documents with >0.9 similarity train-val: 148\n",
            "Max similarity train-test: 0.5370\n",
            "Documents with >0.9 similarity train-test: 0\n",
            "Max similarity val-test: 0.6908\n",
            "Documents with >0.9 similarity val-test: 0\n",
            "\n",
            "============================================================\n",
            "LABEL DISTRIBUTION\n",
            "============================================================\n",
            "\n",
            "Label counts:\n",
            "Train: {0: 4895, 1: 3949, 2: 3681}\n",
            "Validation: {0: 1224, 1: 988, 2: 920}\n",
            "Test: {0: 51, 1: 24, 2: 23}\n",
            "\n",
            "Label percentages:\n",
            "Train: {0: 39.08, 1: 31.53, 2: 29.39}\n",
            "Validation: {0: 39.08, 1: 31.55, 2: 29.37}\n",
            "Test: {0: 52.04, 1: 24.49, 2: 23.47}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class weights (for handling imbalance): [0.85291113 1.05722968 1.13420266]\n",
            "\n",
            "============================================================\n",
            "DATA QUALITY CHECKS\n",
            "============================================================\n",
            "\n",
            "Text length statistics (characters):\n",
            "Train - Min: 2, Max: 184, Mean: 74.6\n",
            "Validation - Min: 3, Max: 144, Mean: 74.3\n",
            "Test - Min: 21, Max: 128, Mean: 81.5\n",
            "\n",
            "Text length statistics (characters):\n",
            "Train - Min: 2, Max: 184, Mean: 74.6\n",
            "Validation - Min: 3, Max: 144, Mean: 74.3\n",
            "Test - Min: 21, Max: 128, Mean: 81.5\n",
            "\n",
            "WARNING: Found very short texts (<3 chars):\n",
            "Train: 2, Validation: 0, Test: 0\n",
            "\n",
            "Sample texts from each set:\n",
            "\n",
            "Train sample:\n",
            "  1. ونبه فضيلته من مايبث عبر القنوات الفضاييه من برامج ومسلسلات هابطهتهدم اخلاق الفرد والمجتمع وتنشرالفس... (label: positive)\n",
            "  2. وتظن انك لن تنجو فلا تدري الا ويرزقك اله سعاده تنسيك كل حزن مرت به... (label: neutral)\n",
            "\n",
            "Validation sample:\n",
            "  1. الماليه تحث ذوي المتوفين المستفيدين باعفاء القروض علي التقدم بطلب عبر موقعها... (label: positive)\n",
            "  2. خادم الحرمين الشريفين يعزي الرييس التركي في ضحايا الهجوم الارهابي الذي وقع في انقره... (label: positive)\n",
            "\n",
            "Test sample:\n",
            "  1. مطار حمد الدولي ينضم لنادي الخمس نجوم مبروك لاداره هذا المطار الجميل... (label: neutral)\n",
            "  2. بيض اله وجه اداره المطار علي حسن الاستقبال وتسهيل السفر والي افرحني اكثر بان الموظفين والمدراء قطرين... (label: neutral)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe2be80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fe2be80",
        "outputId": "9a472615-b235-418e-df2d-15049793874d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "bert = AutoModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "\n",
        "bert.config.hidden_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3496649c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3496649c",
        "outputId": "6985faed-cbda-434d-b6cf-21ac867da8b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader size: 783\n",
            "Val Loader size: 196\n",
            "Test Loader size: 7\n",
            "15751\n",
            "Keys in batch: dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
            "input_ids shape: torch.Size([16, 128])\n",
            "attention_mask shape: torch.Size([16, 128])\n",
            "labels shape: torch.Size([16])\n",
            "Decoded text example: حصه بنت سلمان الاهتمام بالجمعيه والوقوف معها امتداد لعنايه خادم الحرمين بتعليم المراه\n",
            "Label: 2\n",
            "Label: positive\n"
          ]
        }
      ],
      "source": [
        "# Bulid your Bidirectional LSTM with LLM embedding here\n",
        "# 1) build datasets (train and test)\n",
        "# 2) tokenize data\n",
        "# 3) build the model\n",
        "# 4) train the model\n",
        "# 5) evaluate the model\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "MODEL_NAME = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"\n",
        "\n",
        "\n",
        "config = {\n",
        "    'model_name': MODEL_NAME,\n",
        "    # Since tweets are short texts, we limited the maximum sequence length to 128 tokens to reduce computational cost without affecting performance.\n",
        "    'max_len': 128,\n",
        "    'batch_size': 16,\n",
        "    'num_epochs': 10,\n",
        "    'learning_rate': 2e-5,\n",
        "    'weight_decay': 1e-2,\n",
        "    'hidden_size': 128,\n",
        "    'num_layers': 2,\n",
        "    'dropout': 0.3,\n",
        "    'num_classes': 3\n",
        "\n",
        "}\n",
        "class SentimentDataset(Dataset):\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_datasets(train_df, val_df, test_data, config, tokenizer):\n",
        "\n",
        "    train_dataset = SentimentDataset(\n",
        "        texts=list(train_df['cleaned_text']),\n",
        "        labels=list(train_df['label']),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=config['max_len']\n",
        "    )\n",
        "\n",
        "    val_dataset = SentimentDataset(\n",
        "        texts=list(val_df['cleaned_text']),\n",
        "        labels=list(val_df['label']),\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    test_dataset = SentimentDataset(\n",
        "        texts=list(test_data['cleaned_text']),\n",
        "        labels=list(test_data['label']),\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "seed()\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = create_datasets(train_df, val_df, test_df, config, tokenizer)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train Loader size: {len(train_loader)}\")\n",
        "print(f\"Val Loader size: {len(val_loader)}\")\n",
        "print(f\"Test Loader size: {len(test_loader)}\")\n",
        "\n",
        "\n",
        "test_batch = next(iter(train_loader))\n",
        "test_batch\n",
        "print(len(train_data))\n",
        "print(\"Keys in batch:\", test_batch.keys())\n",
        "\n",
        "\n",
        "print(\"input_ids shape:\", test_batch['input_ids'].shape)\n",
        "print(\"attention_mask shape:\", test_batch['attention_mask'].shape)\n",
        "print(\"labels shape:\", test_batch['labels'].shape)\n",
        "\n",
        "\n",
        "decoded_text = tokenizer.decode(\n",
        "    test_batch['input_ids'][0], skip_special_tokens=True)\n",
        "print(\"Decoded text example:\", decoded_text)\n",
        "\n",
        "print(\"Label:\", test_batch['labels'][0].item())\n",
        "print(\"Label:\", mapping(test_batch['labels'][0].item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb_Pqifn_QZO",
      "metadata": {
        "id": "fb_Pqifn_QZO"
      },
      "outputs": [],
      "source": [
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5H0Ta5HbgztV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0Ta5HbgztV",
        "outputId": "875d977a-0ea5-4ae2-94e7-561b188df097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 128, 256])\n",
            "tensor(1.0971, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "seed()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "test_batch = next(iter(train_loader))\n",
        "input_ids = test_batch['input_ids'].to(DEVICE)\n",
        "attention_mask = test_batch['attention_mask'].to(DEVICE)\n",
        "labels = test_batch['labels'].to(DEVICE)\n",
        "\n",
        "bert = bert.to(DEVICE)\n",
        "for params in bert.parameters():\n",
        "    params.requires_grad = False\n",
        "\n",
        "bert_hidden_size = bert.config.hidden_size\n",
        "\n",
        "lstm = nn.LSTM(\n",
        "    input_size=bert_hidden_size,\n",
        "    hidden_size=config['hidden_size'],\n",
        "    num_layers=config['num_layers'],\n",
        "    batch_first=True,\n",
        "    dropout=config['dropout'],\n",
        "    bidirectional=True\n",
        "\n",
        ").to(DEVICE)\n",
        "\n",
        "\n",
        "attention = nn.Linear(config['hidden_size'] * 2, 1).to(DEVICE)\n",
        "norm = nn.LayerNorm(config['hidden_size'] * 2).to(DEVICE)\n",
        "fc = nn.Linear(config['hidden_size'] * 2, config['num_classes']).to(DEVICE)\n",
        "\n",
        "dropout1 = nn.Dropout(config['dropout']).to(DEVICE)\n",
        "dropout2 = nn.Dropout(config['dropout']).to(DEVICE)\n",
        "\n",
        "\n",
        "# [batch_size, seq_len, bert_hidden_size]\n",
        "out = bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# [batch_size, seq_len, hidden_size*2]\n",
        "lstm_out, _ = lstm(out.last_hidden_state)\n",
        "print(lstm_out.shape)\n",
        "lstm_out_norm = norm(lstm_out)\n",
        "attention_scores = attention(lstm_out_norm)  # [batch_size, seq_len, 1]\n",
        "\n",
        "# Convert scores to probabilities using softmax\n",
        "attention_weights = torch.softmax( attention_scores, dim=1)  # [batch_size, seq_len, 1]\n",
        "attention_weights.shape\n",
        "\n",
        "# Element-wise multiplication (broadcasting)\n",
        "# [batch_size, seq_len, hidden_size*2]\n",
        "weighted_outputs = attention_weights * lstm_out\n",
        "\n",
        "# Sum across sequence dimension to get context vector\n",
        "# [batch_size, hidden_size*2]\n",
        "context_vector = torch.sum(weighted_outputs, dim=1)\n",
        "\n",
        "# context_vector = norm(context_vector)\n",
        "context_vector = dropout2(context_vector)\n",
        "\n",
        "\n",
        "logits = fc(context_vector)  # [batch_size, num_classes]\n",
        "\n",
        "\n",
        "loss = loss_fn(logits, labels)\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from transformers import AutoModel\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "class BiLSTMWithLLM(nn.Module):\n",
        "    def __init__(self, model_name, hidden_size, num_layers, dropout, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Freeze first N layers\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "        bert_hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        # BiLSTM with dropout\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=bert_hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
        "        self.norm = nn.LayerNorm(hidden_size * 2)\n",
        "\n",
        "        # Better classifier with LayerNorm\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_size * 2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get BERT embeddings\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        # LSTM\n",
        "        lstm_out, _ = self.lstm(sequence_output)\n",
        "\n",
        "        lstm_out = self.norm(lstm_out)\n",
        "\n",
        "        # Attention\n",
        "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
        "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(context_vector)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device):\n",
        "\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    train_loop = tqdm(train_loader, desc=\"Train\", leave=True)\n",
        "\n",
        "    for batch in train_loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        train_loop.set_postfix(train_loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    val_loop = tqdm(val_loader, desc=\"Val\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            batch_acc = (preds == labels).float().mean().item()\n",
        "            val_loop.set_postfix(\n",
        "                val_loss=f\"{loss.item():.4f}\", batch_acc=f\"{batch_acc:.4f}\")\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "    return avg_train_loss, avg_val_loss, val_acc, val_f1\n",
        "\n",
        "\n",
        "def test_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    loop = tqdm(dataloader, desc=\"Evaluating\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loop:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            labels = batch['labels'].to(DEVICE)\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            batch_acc = (preds == labels).float().mean().item()\n",
        "            loop.set_postfix(batch_accuracy=f\"{batch_acc:.4f}\")\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    return accuracy, f1, cm\n",
        "\n",
        "\n",
        "seed()\n",
        "\n",
        "\n",
        "config = {\n",
        "    'model_name': MODEL_NAME,\n",
        "    'max_len': 128,\n",
        "    'batch_size': 8,\n",
        "    'num_epochs': 10,\n",
        "    'learning_rate': 2e-5,\n",
        "    'weight_decay': 1e-2,\n",
        "    'hidden_size': 128,\n",
        "    'num_layers': 2,\n",
        "    'dropout': 0.1,\n",
        "    'num_classes': 3\n",
        "\n",
        "}\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train Loader size: {len(train_loader)}\")\n",
        "print(f\"Val Loader size: {len(val_loader)}\")\n",
        "print(f\"Test Loader size: {len(test_loader)}\")\n",
        "\n",
        "\n",
        "\n",
        "model = BiLSTMWithLLM(\n",
        "    model_name=config['model_name'],\n",
        "    hidden_size=config['hidden_size'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dropout=config['dropout'],\n",
        "    num_classes=config['num_classes']\n",
        ").to(DEVICE)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    weight_decay=config['weight_decay']\n",
        ")\n",
        "\n",
        "\n",
        "best_accuracy = 0.0\n",
        "\n",
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "    train_loss, val_loss, val_acc, val_f1 = train_model(\n",
        "        model, train_loader, val_loader, optimizer, criterion, DEVICE\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f}\")\n",
        "    print(f\"Val Acc:    {val_acc:.4f}\")\n",
        "    print(f\"Val F1:     {val_f1:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "    test_accuracy, test_f1, test_cm = test_model(model, test_loader)\n",
        "    if best_accuracy < test_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saving best model weights\")\n",
        "\n",
        "    print(\"TEST RESULTS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TEST Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"TEST F1 Score: {test_f1:.4f}\")\n",
        "    print(\"TEST Confusion Matrix:\")\n",
        "    print(test_cm)\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rBmfwD-vfjwk",
        "outputId": "80414e8e-9561-4b20-c956-2aae0bcd43ae"
      },
      "id": "rBmfwD-vfjwk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader size: 1566\n",
            "Val Loader size: 392\n",
            "Test Loader size: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.56it/s, train_loss=0.5992]\n",
            "Val: 100%|██████████| 392/392 [00:23<00:00, 16.38it/s, batch_acc=1.0000, val_loss=0.0139]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train Loss: 0.4753\n",
            "Val Loss:   0.3659\n",
            "Val Acc:    0.8582\n",
            "Val F1:     0.8584\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 13.14it/s, batch_accuracy=0.5000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model weights\n",
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8163\n",
            "TEST F1 Score: 0.8188\n",
            "TEST Confusion Matrix:\n",
            "[[40  5  6]\n",
            " [ 2 19  3]\n",
            " [ 1  1 21]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.55it/s, train_loss=0.5445]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.32it/s, batch_acc=1.0000, val_loss=0.0089]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "Train Loss: 0.3545\n",
            "Val Loss:   0.3252\n",
            "Val Acc:    0.8716\n",
            "Val F1:     0.8717\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 13.29it/s, batch_accuracy=0.5000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model weights\n",
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8265\n",
            "TEST F1 Score: 0.8298\n",
            "TEST Confusion Matrix:\n",
            "[[44  3  4]\n",
            " [ 1 18  5]\n",
            " [ 2  2 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.54it/s, train_loss=0.0740]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.32it/s, batch_acc=1.0000, val_loss=0.0094]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "Train Loss: 0.3120\n",
            "Val Loss:   0.3102\n",
            "Val Acc:    0.8806\n",
            "Val F1:     0.8811\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 13.27it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7755\n",
            "TEST F1 Score: 0.7817\n",
            "TEST Confusion Matrix:\n",
            "[[38  8  5]\n",
            " [ 0 19  5]\n",
            " [ 2  2 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   4%|▍         | 66/1566 [00:04<01:48, 13.86it/s, train_loss=0.1957]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3433578062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     train_loss, val_loss, val_acc, val_f1 = train_model(\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     )\n",
            "\u001b[0;32m/tmp/ipython-input-3433578062.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{loss.item():.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc0pCWoak4G2",
        "outputId": "71bfa95f-896b-48e5-c59c-c1291636b8da"
      },
      "id": "oc0pCWoak4G2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.826530612244898"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from transformers import AutoModel\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from torch.optim import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#  trying to change the Classification laysers\n",
        "\n",
        "\n",
        "class BiLSTMWithLLM(nn.Module):\n",
        "    def __init__(self, model_name, hidden_size, num_layers, dropout, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        # Freeze first N layers\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "        bert_hidden_size = self.bert.config.hidden_size\n",
        "\n",
        "        # BiLSTM with dropout\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=bert_hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0\n",
        "        )\n",
        "\n",
        "        # Attention mechanism\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "        # Classification head with more layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Get BERT embeddings\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        # LSTM\n",
        "        lstm_out, _ = self.lstm(sequence_output)\n",
        "\n",
        "        # Attention\n",
        "        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
        "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(context_vector)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device):\n",
        "\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    train_loop = tqdm(train_loader, desc=\"Train\", leave=True)\n",
        "\n",
        "    for batch in train_loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        train_loop.set_postfix(train_loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    val_loop = tqdm(val_loader, desc=\"Val\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            batch_acc = (preds == labels).float().mean().item()\n",
        "            val_loop.set_postfix(\n",
        "                val_loss=f\"{loss.item():.4f}\", batch_acc=f\"{batch_acc:.4f}\")\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "    return avg_train_loss, avg_val_loss, val_acc, val_f1\n",
        "\n",
        "\n",
        "def test_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    loop = tqdm(dataloader, desc=\"Evaluating\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loop:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            labels = batch['labels'].to(DEVICE)\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            batch_acc = (preds == labels).float().mean().item()\n",
        "            loop.set_postfix(batch_accuracy=f\"{batch_acc:.4f}\")\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    return accuracy, f1, cm\n",
        "\n",
        "\n",
        "seed()\n",
        "\n",
        "\n",
        "config = {\n",
        "    'model_name': MODEL_NAME,\n",
        "    'max_len': 128,\n",
        "    'batch_size': 8,\n",
        "    'num_epochs': 10,\n",
        "    'learning_rate': 2e-5,\n",
        "    'weight_decay': 1e-2,\n",
        "    'hidden_size': 128,\n",
        "    'num_layers': 2,\n",
        "    'dropout': 0.1,\n",
        "    'num_classes': 3\n",
        "\n",
        "}\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train Loader size: {len(train_loader)}\")\n",
        "print(f\"Val Loader size: {len(val_loader)}\")\n",
        "print(f\"Test Loader size: {len(test_loader)}\")\n",
        "\n",
        "\n",
        "\n",
        "model = BiLSTMWithLLM(\n",
        "    model_name=config['model_name'],\n",
        "    hidden_size=config['hidden_size'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dropout=config['dropout'],\n",
        "    num_classes=config['num_classes']\n",
        ").to(DEVICE)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    weight_decay=config['weight_decay']\n",
        ")\n",
        "\n",
        "\n",
        "best_accuracy = 0.0\n",
        "\n",
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "    train_loss, val_loss, val_acc, val_f1 = train_model(\n",
        "        model, train_loader, val_loader, optimizer, criterion, DEVICE\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f}\")\n",
        "    print(f\"Val Acc:    {val_acc:.4f}\")\n",
        "    print(f\"Val F1:     {val_f1:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "    test_accuracy, test_f1, test_cm = test_model(model, test_loader)\n",
        "    if best_accuracy < test_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saving best model weights\")\n",
        "\n",
        "    print(\"TEST RESULTS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TEST Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"TEST F1 Score: {test_f1:.4f}\")\n",
        "    print(\"TEST Confusion Matrix:\")\n",
        "    print(test_cm)\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e79Lr8USyDgr",
        "outputId": "7188bc69-257d-4a5b-d64d-567fdd04aadb"
      },
      "id": "e79Lr8USyDgr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loader size: 1566\n",
            "Val Loader size: 392\n",
            "Test Loader size: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.60it/s, train_loss=0.3198]\n",
            "Val: 100%|██████████| 392/392 [00:23<00:00, 16.38it/s, batch_acc=1.0000, val_loss=0.0242]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train Loss: 0.5581\n",
            "Val Loss:   0.3773\n",
            "Val Acc:    0.8566\n",
            "Val F1:     0.8568\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.68it/s, batch_accuracy=0.5000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best model weights\n",
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8367\n",
            "TEST F1 Score: 0.8374\n",
            "TEST Confusion Matrix:\n",
            "[[45  3  3]\n",
            " [ 2 19  3]\n",
            " [ 3  2 18]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.55it/s, train_loss=0.1667]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.28it/s, batch_acc=1.0000, val_loss=0.0105]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "Train Loss: 0.3632\n",
            "Val Loss:   0.3284\n",
            "Val Acc:    0.8736\n",
            "Val F1:     0.8736\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.49it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8163\n",
            "TEST F1 Score: 0.8228\n",
            "TEST Confusion Matrix:\n",
            "[[41  2  8]\n",
            " [ 0 20  4]\n",
            " [ 3  1 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.64it/s, train_loss=0.1475]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.29it/s, batch_acc=1.0000, val_loss=0.0074]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "Train Loss: 0.3256\n",
            "Val Loss:   0.3129\n",
            "Val Acc:    0.8777\n",
            "Val F1:     0.8780\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.41it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7755\n",
            "TEST F1 Score: 0.7851\n",
            "TEST Confusion Matrix:\n",
            "[[37  3 11]\n",
            " [ 0 20  4]\n",
            " [ 1  3 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.60it/s, train_loss=0.0728]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.29it/s, batch_acc=1.0000, val_loss=0.0050]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n",
            "Train Loss: 0.2986\n",
            "Val Loss:   0.3001\n",
            "Val Acc:    0.8892\n",
            "Val F1:     0.8894\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.43it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8265\n",
            "TEST F1 Score: 0.8308\n",
            "TEST Confusion Matrix:\n",
            "[[43  2  6]\n",
            " [ 0 20  4]\n",
            " [ 4  1 18]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.56it/s, train_loss=0.5921]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.18it/s, batch_acc=1.0000, val_loss=0.0046]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5\n",
            "Train Loss: 0.2700\n",
            "Val Loss:   0.3006\n",
            "Val Acc:    0.8847\n",
            "Val F1:     0.8851\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 11.22it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7959\n",
            "TEST F1 Score: 0.8036\n",
            "TEST Confusion Matrix:\n",
            "[[39  4  8]\n",
            " [ 0 19  5]\n",
            " [ 1  2 20]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.65it/s, train_loss=0.1535]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.31it/s, batch_acc=1.0000, val_loss=0.0033]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6\n",
            "Train Loss: 0.2510\n",
            "Val Loss:   0.3218\n",
            "Val Acc:    0.8803\n",
            "Val F1:     0.8809\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.48it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7653\n",
            "TEST F1 Score: 0.7709\n",
            "TEST Confusion Matrix:\n",
            "[[38  8  5]\n",
            " [ 0 20  4]\n",
            " [ 3  3 17]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.62it/s, train_loss=0.1659]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.03it/s, batch_acc=1.0000, val_loss=0.0023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7\n",
            "Train Loss: 0.2371\n",
            "Val Loss:   0.3060\n",
            "Val Acc:    0.8889\n",
            "Val F1:     0.8889\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 10.62it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8163\n",
            "TEST F1 Score: 0.8202\n",
            "TEST Confusion Matrix:\n",
            "[[42  2  7]\n",
            " [ 1 20  3]\n",
            " [ 4  1 18]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:42<00:00, 15.24it/s, train_loss=0.1313]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.29it/s, batch_acc=1.0000, val_loss=0.0023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8\n",
            "Train Loss: 0.2176\n",
            "Val Loss:   0.3009\n",
            "Val Acc:    0.8930\n",
            "Val F1:     0.8931\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.55it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7653\n",
            "TEST F1 Score: 0.7726\n",
            "TEST Confusion Matrix:\n",
            "[[38  3 10]\n",
            " [ 0 20  4]\n",
            " [ 5  1 17]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.60it/s, train_loss=0.0785]\n",
            "Val: 100%|██████████| 392/392 [00:24<00:00, 16.24it/s, batch_acc=1.0000, val_loss=0.0016]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9\n",
            "Train Loss: 0.2056\n",
            "Val Loss:   0.3108\n",
            "Val Acc:    0.8889\n",
            "Val F1:     0.8891\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 11.15it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7959\n",
            "TEST F1 Score: 0.8023\n",
            "TEST Confusion Matrix:\n",
            "[[39  4  8]\n",
            " [ 0 20  4]\n",
            " [ 2  2 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 1566/1566 [01:40<00:00, 15.58it/s, train_loss=0.0033]\n",
            "Val: 100%|██████████| 392/392 [00:23<00:00, 16.34it/s, batch_acc=1.0000, val_loss=0.0013]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10\n",
            "Train Loss: 0.1903\n",
            "Val Loss:   0.3089\n",
            "Val Acc:    0.8914\n",
            "Val F1:     0.8916\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 13/13 [00:01<00:00, 12.54it/s, batch_accuracy=1.0000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8061\n",
            "TEST F1 Score: 0.8124\n",
            "TEST Confusion Matrix:\n",
            "[[41  3  7]\n",
            " [ 0 19  5]\n",
            " [ 3  1 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrvwR9LK2IvD",
        "outputId": "7c73293b-1aa3-4258-e884-94e87911ca97"
      },
      "id": "NrvwR9LK2IvD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8367346938775511"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = BiLSTMWithLLM(\n",
        "    model_name=config['model_name'],\n",
        "    hidden_size=config['hidden_size'],\n",
        "    num_layers=config['num_layers'],\n",
        "    dropout=config['dropout'],\n",
        "    num_classes=config['num_classes']\n",
        ").to(DEVICE)\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        labels = batch['labels'].to(DEVICE)\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        batch_acc = (preds == labels).float().mean().item()\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    print(\"TEST RESULTS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TEST Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"TEST F1 Score: {f1:.4f}\")\n",
        "    print(\"TEST Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 50)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9OdOEav2Puf",
        "outputId": "862846df-a41b-4de9-b985-3e81d22d2ccf"
      },
      "id": "w9OdOEav2Puf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8367\n",
            "TEST F1 Score: 0.8374\n",
            "TEST Confusion Matrix:\n",
            "[[45  3  3]\n",
            " [ 2 19  3]\n",
            " [ 3  2 18]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2454f07e",
      "metadata": {
        "id": "2454f07e"
      },
      "source": [
        "## Part (2) LLM for Arabic SA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9a8ee824",
      "metadata": {
        "id": "9a8ee824"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ca9f9e95",
      "metadata": {
        "id": "ca9f9e95"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "# Data preprocessing function\n",
        "# In this function you should clean the Arabic text and normlize it\n",
        "# remove repeated letter, english letter, punctuation, etc.\n",
        "# Input: unclean tweet\n",
        "# Output: clean tweet\n",
        "\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    # remove english letters\n",
        "    tweet = re.sub(r'[a-zA-Z0-9]+', '', tweet, flags=re.MULTILINE)\n",
        "    '''\n",
        "    write your code here\n",
        "    '''\n",
        "    return tweet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MODEL_NAME = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"\n",
        "from datasets import Dataset\n",
        "\n",
        "train = Dataset.from_pandas(train_df)\n",
        "val   = Dataset.from_pandas(val_df)\n",
        "test  = Dataset.from_pandas(test_df)\n",
        "train.take(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYO1JhOqqAxu",
        "outputId": "c2a74afd-4f4f-4c6c-bf31-8bed503d79e1"
      },
      "id": "gYO1JhOqqAxu",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tweet', 'label', 'cleaned_text', '__index_level_0__'],\n",
              "    num_rows: 4\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bulid your Bidirectional LSTM with LLM embedding here\n",
        "# 1) build datasets (train and test)\n",
        "# 2) call tokenizer and pre-trained model\n",
        "# 3) prepare trainer\n",
        "# 4) train the model (call trainer)\n",
        "# 5) evaluate the model\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, preds),\n",
        "        \"f1_macro\": f1_score(labels, preds, average=\"macro\")\n",
        "    }\n",
        "\n",
        "def tokenize_function(batch):\n",
        "    tokens = tokenizer(\n",
        "        batch[\"cleaned_text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=config[\"max_len\"]\n",
        "    )\n",
        "    tokens[\"labels\"] = batch[\"label\"]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MODEL_NAME = \"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\"\n",
        "\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3\n",
        ").to(DEVICE)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "\n",
        "data_collator = DataCollatorWithPadding(\n",
        "    tokenizer=tokenizer,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = train.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=train.column_names\n",
        ")\n",
        "\n",
        "val_dataset = val.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=val.column_names\n",
        ")\n",
        "\n",
        "test_dataset = test.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=test.column_names\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363,
          "referenced_widgets": [
            "6956a179b7214dd4a8af218b6c1e7a55",
            "44d13b6ec1cf413092a68acd74311135",
            "ee8f1894d2414feaa9bbfe156b9d6d68",
            "c4138cd052fb472a86e1997e3b55150b",
            "a8caf08ed42141e98f58cdcb2c8bb226",
            "500444a198944250a5081002e144dac5",
            "b715f8ac2af34ad9b125b51a5e313c76",
            "93a37a32b4e04df69f8e73e6ae2b5db6",
            "36fca747a5ac4a41b2471dd02088f593",
            "8e3c97ec80f84373beae061b5bf47015",
            "47b62fccbd9345349a14d5259488adef",
            "bb6df5becffd40fea88f9c2edaa5a667",
            "4bb81c4c634d46c3b723d5def62c02e1",
            "0dad86eda53a440aae50ed016b8ac73a",
            "5f829d53eedd459fa7a6b4e9e17a0eee",
            "6086a962eaa34f93ba8f063fa82abcf9",
            "acb617fc2ef54dd288f10be1c8734078",
            "de09388e0b664560a7296874bd16e768",
            "0f05d6159f78443b9eddf76bd69d3231",
            "36283f3a55384a5bba3606615aa619cc",
            "d769a885a2814226b7c4f87f47a9a389",
            "3e6185b78bf5495faf6b6c6a5d0c2919",
            "4d8be5a432e94e01965e453a2f79476e",
            "edbc28e517cb40c599b724bfb0b72fcb",
            "49847b23fd5b4cb39f6d66643c37b819",
            "512af87a48cc4c298b30a8c9039e20c6",
            "b7483b943986435ca017032450083d7b",
            "ef90f72b4d234cdb99461bb4b41a5bb1",
            "e0583b2824f94590a07557cfea8c5891",
            "cb019f43eb90419a84e03660c96fabf6",
            "7f6546c3522e4cbfa782c8af87f4a9c3",
            "293ca5604a8142b99599fb8ef8f5ba8f",
            "29f03bb57b6344b4a39cbc1c0ac7a905"
          ]
        },
        "id": "ni9n01O3pDOO",
        "outputId": "ce687ce6-67d2-4b25-8b73-4c7eac5895a1"
      },
      "id": "ni9n01O3pDOO",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12562 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6956a179b7214dd4a8af218b6c1e7a55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3141 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb6df5becffd40fea88f9c2edaa5a667"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d8be5a432e94e01965e453a2f79476e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3930' max='3930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3930/3930 27:44, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.342900</td>\n",
              "      <td>0.219268</td>\n",
              "      <td>0.934734</td>\n",
              "      <td>0.934306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>0.270952</td>\n",
              "      <td>0.933461</td>\n",
              "      <td>0.932130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.059000</td>\n",
              "      <td>0.346156</td>\n",
              "      <td>0.939510</td>\n",
              "      <td>0.938522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>0.371420</td>\n",
              "      <td>0.941420</td>\n",
              "      <td>0.940528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.008200</td>\n",
              "      <td>0.390731</td>\n",
              "      <td>0.941420</td>\n",
              "      <td>0.940334</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3930, training_loss=0.09423793150875101, metrics={'train_runtime': 1665.1954, 'train_samples_per_second': 37.719, 'train_steps_per_second': 2.36, 'total_flos': 4131538441873920.0, 'train_loss': 0.09423793150875101, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(test_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "eZ7APly1rhay",
        "outputId": "15aa16fa-c97a-4f33-82a0-8ebae5480dd3"
      },
      "id": "eZ7APly1rhay",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7/7 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 2.44217586517334,\n",
              " 'eval_accuracy': 0.6868686868686869,\n",
              " 'eval_f1_macro': 0.6822229910685683,\n",
              " 'eval_runtime': 0.7878,\n",
              " 'eval_samples_per_second': 125.671,\n",
              " 'eval_steps_per_second': 8.886,\n",
              " 'epoch': 5.0}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##: Fine-Tuning without using Trainer"
      ],
      "metadata": {
        "id": "HpgppncQuPHM"
      },
      "id": "HpgppncQuPHM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2127e8ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2127e8ce",
        "outputId": "be5d6d02-9410-4953-89b7-08cfc58ba2c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:32<00:00,  2.87it/s, train_loss=0.3216]\n",
            "Val: 100%|██████████| 196/196 [00:23<00:00,  8.34it/s, batch_acc=0.9167, val_loss=0.3661]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train Loss: 0.3311\n",
            "Val Loss:   0.2187\n",
            "Val Acc:    0.9237\n",
            "Val F1:     0.9237\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:31<00:00,  2.89it/s, train_loss=0.0030]\n",
            "Val: 100%|██████████| 196/196 [00:23<00:00,  8.32it/s, batch_acc=0.9167, val_loss=0.2629]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "Train Loss: 0.1258\n",
            "Val Loss:   0.2303\n",
            "Val Acc:    0.9227\n",
            "Val F1:     0.9228\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:31<00:00,  2.88it/s, train_loss=0.0009]\n",
            "Val: 100%|██████████| 196/196 [00:23<00:00,  8.34it/s, batch_acc=0.9167, val_loss=0.3053]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "Train Loss: 0.0489\n",
            "Val Loss:   0.3384\n",
            "Val Acc:    0.9221\n",
            "Val F1:     0.9222\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:31<00:00,  2.89it/s, train_loss=0.0015]\n",
            "Val: 100%|██████████| 196/196 [00:23<00:00,  8.33it/s, batch_acc=0.9167, val_loss=0.4999]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n",
            "Train Loss: 0.0333\n",
            "Val Loss:   0.3002\n",
            "Val Acc:    0.9208\n",
            "Val F1:     0.9209\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  9.60it/s, batch_accuracy=1.0000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7041\n",
            "TEST F1 Score: 0.7090\n",
            "TEST Confusion Matrix:\n",
            "[[31  7 13]\n",
            " [ 0 22  2]\n",
            " [ 2  5 16]]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device):\n",
        "\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    train_loop = tqdm(train_loader, desc=\"Train\", leave=True)\n",
        "\n",
        "    for batch in train_loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        train_loop.set_postfix(train_loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    val_loop = tqdm(val_loader, desc=\"Val\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            logits = outputs.logits\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            batch_acc = (preds == labels).float().mean().item()\n",
        "            val_loop.set_postfix(\n",
        "                val_loss=f\"{loss.item():.4f}\", batch_acc=f\"{batch_acc:.4f}\")\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "    return avg_train_loss, avg_val_loss, val_acc, val_f1\n",
        "\n",
        "\n",
        "def test_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    loop = tqdm(dataloader, desc=\"Evaluating\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loop:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            labels = batch['labels'].to(DEVICE)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            _, preds = torch.max(logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            batch_acc = (preds == labels).float().mean().item()\n",
        "            loop.set_postfix(batch_accuracy=f\"{batch_acc:.4f}\")\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    return accuracy, f1, cm\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3\n",
        ").to(DEVICE)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "train_dataset, val_dataset, test_dataset = create_datasets(train_df, val_df, test_df, config, tokenizer)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    weight_decay=config['weight_decay']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "config['num_epochs'] = 4\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        labels = batch['labels'].to(DEVICE)\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        _, preds = torch.max(logits, dim=1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        batch_acc = (preds == labels).float().mean().item()\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    cm = confusion_matrix(true_labels, predictions)\n",
        "    print(\"TEST RESULTS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TEST Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"TEST F1 Score: {f1:.4f}\")\n",
        "    print(\"TEST Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "test_accuracy, test_f1, test_cm = test_model(model, test_loader)\n",
        "print(\"TEST RESULTS\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"TEST Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"TEST F1 Score: {test_f1:.4f}\")\n",
        "print(\"TEST Confusion Matrix:\")\n",
        "print(test_cm)\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "    train_loss, val_loss, val_acc, val_f1 = train_model(\n",
        "        model, train_loader, val_loader, optimizer, criterion, DEVICE\n",
        "    )\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}\")\n",
        "    print(f\"Val Loss:   {val_loss:.4f}\")\n",
        "    print(f\"Val Acc:    {val_acc:.4f}\")\n",
        "    print(f\"Val F1:     {val_f1:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "    test_accuracy, test_f1, test_cm = test_model(model, test_loader)\n",
        "    if best_accuracy < test_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saving best model weights\")\n",
        "\n",
        "    print(\"TEST RESULTS\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"TEST Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"TEST F1 Score: {test_f1:.4f}\")\n",
        "    print(\"TEST Confusion Matrix:\")\n",
        "    print(test_cm)\n",
        "    print(\"-\" * 50)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "test_accuracy, test_f1, test_cm = test_model(model, test_loader)\n",
        "print(\"TEST RESULTS\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"TEST Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"TEST F1 Score: {test_f1:.4f}\")\n",
        "print(\"TEST Confusion Matrix:\")\n",
        "print(test_cm)\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v25_0jBgtuXq",
        "outputId": "d8e538fe-830e-4199-caf5-7369d2602ecc"
      },
      "id": "v25_0jBgtuXq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:48<00:00,  2.71it/s, train_loss=0.0005]\n",
            "Val: 100%|██████████| 196/196 [00:25<00:00,  7.58it/s, batch_acc=0.9167, val_loss=0.5067]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train Loss: 0.0185\n",
            "Val Loss:   0.3499\n",
            "Val Acc:    0.9208\n",
            "Val F1:     0.9209\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  9.36it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.6837\n",
            "TEST F1 Score: 0.6933\n",
            "TEST Confusion Matrix:\n",
            "[[31  7 13]\n",
            " [ 0 18  6]\n",
            " [ 3  2 18]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:47<00:00,  2.72it/s, train_loss=0.0387]\n",
            "Val: 100%|██████████| 196/196 [00:25<00:00,  7.63it/s, batch_acc=0.9167, val_loss=0.3525]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "Train Loss: 0.0166\n",
            "Val Loss:   0.3580\n",
            "Val Acc:    0.9221\n",
            "Val F1:     0.9221\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  8.97it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7041\n",
            "TEST F1 Score: 0.7133\n",
            "TEST Confusion Matrix:\n",
            "[[32  7 12]\n",
            " [ 0 18  6]\n",
            " [ 2  2 19]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:48<00:00,  2.72it/s, train_loss=0.0002]\n",
            "Val: 100%|██████████| 196/196 [00:25<00:00,  7.61it/s, batch_acc=0.9167, val_loss=0.7703]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3\n",
            "Train Loss: 0.0113\n",
            "Val Loss:   0.4697\n",
            "Val Acc:    0.9154\n",
            "Val F1:     0.9154\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  8.46it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7347\n",
            "TEST F1 Score: 0.7410\n",
            "TEST Confusion Matrix:\n",
            "[[36  6  9]\n",
            " [ 0 20  4]\n",
            " [ 4  3 16]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 783/783 [04:35<00:00,  2.84it/s, train_loss=0.0003]\n",
            "Val: 100%|██████████| 196/196 [00:23<00:00,  8.30it/s, batch_acc=0.9167, val_loss=0.4841]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4\n",
            "Train Loss: 0.0152\n",
            "Val Loss:   0.4032\n",
            "Val Acc:    0.9163\n",
            "Val F1:     0.9162\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  9.56it/s, batch_accuracy=1.0000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.7245\n",
            "TEST F1 Score: 0.7360\n",
            "TEST Confusion Matrix:\n",
            "[[33  4 14]\n",
            " [ 0 18  6]\n",
            " [ 2  1 20]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 7/7 [00:00<00:00,  9.65it/s, batch_accuracy=1.0000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST RESULTS\n",
            "--------------------------------------------------\n",
            "TEST Accuracy: 0.8163\n",
            "TEST F1 Score: 0.8174\n",
            "TEST Confusion Matrix:\n",
            "[[39  5  7]\n",
            " [ 1 22  1]\n",
            " [ 3  1 19]]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Results\n",
        "\n",
        "## Model Performance Comparison\n",
        "\n",
        "| Model / Approach                         | Accuracy |\n",
        "|-----------------------------------------|----------|\n",
        "| LSTM with LLM Embeddings                | 0.8367   |\n",
        "| Fine-Tuning (without using Trainer)     | 0.8163   |\n",
        "| Fine-Tuning using Trainer (Validation)  | 0.9414   |\n",
        "| Fine-Tuning using Trainer (Test)        | 0.6869   |\n",
        "\n",
        "## Summary of Results\n",
        "\n",
        "The experimental results indicate that integrating an LSTM layer with LLM-based embeddings achieved higher performance compared to direct fine-tuning without the HuggingFace Trainer. Specifically, the LSTM with LLM embeddings reached an accuracy of **0.8367**, while the fine-tuning approach without using the Trainer framework achieved an accuracy of **0.8163**.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DCGbs5lUxmhq"
      },
      "id": "DCGbs5lUxmhq"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gk5iV35R0nOj"
      },
      "id": "Gk5iV35R0nOj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "HpgppncQuPHM"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6956a179b7214dd4a8af218b6c1e7a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44d13b6ec1cf413092a68acd74311135",
              "IPY_MODEL_ee8f1894d2414feaa9bbfe156b9d6d68",
              "IPY_MODEL_c4138cd052fb472a86e1997e3b55150b"
            ],
            "layout": "IPY_MODEL_a8caf08ed42141e98f58cdcb2c8bb226"
          }
        },
        "44d13b6ec1cf413092a68acd74311135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500444a198944250a5081002e144dac5",
            "placeholder": "​",
            "style": "IPY_MODEL_b715f8ac2af34ad9b125b51a5e313c76",
            "value": "Map: 100%"
          }
        },
        "ee8f1894d2414feaa9bbfe156b9d6d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93a37a32b4e04df69f8e73e6ae2b5db6",
            "max": 12562,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36fca747a5ac4a41b2471dd02088f593",
            "value": 12562
          }
        },
        "c4138cd052fb472a86e1997e3b55150b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e3c97ec80f84373beae061b5bf47015",
            "placeholder": "​",
            "style": "IPY_MODEL_47b62fccbd9345349a14d5259488adef",
            "value": " 12562/12562 [00:03&lt;00:00, 2825.02 examples/s]"
          }
        },
        "a8caf08ed42141e98f58cdcb2c8bb226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500444a198944250a5081002e144dac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b715f8ac2af34ad9b125b51a5e313c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93a37a32b4e04df69f8e73e6ae2b5db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36fca747a5ac4a41b2471dd02088f593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e3c97ec80f84373beae061b5bf47015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b62fccbd9345349a14d5259488adef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb6df5becffd40fea88f9c2edaa5a667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bb81c4c634d46c3b723d5def62c02e1",
              "IPY_MODEL_0dad86eda53a440aae50ed016b8ac73a",
              "IPY_MODEL_5f829d53eedd459fa7a6b4e9e17a0eee"
            ],
            "layout": "IPY_MODEL_6086a962eaa34f93ba8f063fa82abcf9"
          }
        },
        "4bb81c4c634d46c3b723d5def62c02e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb617fc2ef54dd288f10be1c8734078",
            "placeholder": "​",
            "style": "IPY_MODEL_de09388e0b664560a7296874bd16e768",
            "value": "Map: 100%"
          }
        },
        "0dad86eda53a440aae50ed016b8ac73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f05d6159f78443b9eddf76bd69d3231",
            "max": 3141,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36283f3a55384a5bba3606615aa619cc",
            "value": 3141
          }
        },
        "5f829d53eedd459fa7a6b4e9e17a0eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d769a885a2814226b7c4f87f47a9a389",
            "placeholder": "​",
            "style": "IPY_MODEL_3e6185b78bf5495faf6b6c6a5d0c2919",
            "value": " 3141/3141 [00:00&lt;00:00, 3269.26 examples/s]"
          }
        },
        "6086a962eaa34f93ba8f063fa82abcf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb617fc2ef54dd288f10be1c8734078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de09388e0b664560a7296874bd16e768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f05d6159f78443b9eddf76bd69d3231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36283f3a55384a5bba3606615aa619cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d769a885a2814226b7c4f87f47a9a389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6185b78bf5495faf6b6c6a5d0c2919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d8be5a432e94e01965e453a2f79476e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edbc28e517cb40c599b724bfb0b72fcb",
              "IPY_MODEL_49847b23fd5b4cb39f6d66643c37b819",
              "IPY_MODEL_512af87a48cc4c298b30a8c9039e20c6"
            ],
            "layout": "IPY_MODEL_b7483b943986435ca017032450083d7b"
          }
        },
        "edbc28e517cb40c599b724bfb0b72fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef90f72b4d234cdb99461bb4b41a5bb1",
            "placeholder": "​",
            "style": "IPY_MODEL_e0583b2824f94590a07557cfea8c5891",
            "value": "Map: 100%"
          }
        },
        "49847b23fd5b4cb39f6d66643c37b819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb019f43eb90419a84e03660c96fabf6",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f6546c3522e4cbfa782c8af87f4a9c3",
            "value": 99
          }
        },
        "512af87a48cc4c298b30a8c9039e20c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_293ca5604a8142b99599fb8ef8f5ba8f",
            "placeholder": "​",
            "style": "IPY_MODEL_29f03bb57b6344b4a39cbc1c0ac7a905",
            "value": " 99/99 [00:00&lt;00:00, 1555.77 examples/s]"
          }
        },
        "b7483b943986435ca017032450083d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef90f72b4d234cdb99461bb4b41a5bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0583b2824f94590a07557cfea8c5891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb019f43eb90419a84e03660c96fabf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6546c3522e4cbfa782c8af87f4a9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "293ca5604a8142b99599fb8ef8f5ba8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f03bb57b6344b4a39cbc1c0ac7a905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}